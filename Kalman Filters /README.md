# LiDAR and Radar fusion with Kalman Filters, Extended Kalman Filter (EKF) and Unscented Kalman Filter 
## Kalman filters
Kalman filters provide estimations over a continuous state, which allows us to estimate future locations and velocities based on positional data.
In Kalman filters, the probability distribution is given by a **Gaussian**. A Gaussian is a unimodal continuous function over a space of inputs - locations, in this case. Like all probability distributions, the area underneath a Gaussian equals one. 

![image](https://github.com/user-attachments/assets/690be038-c800-4a29-ab08-d06ca24566ac)

A Gaussian is characterized by two parameters: 
-	Mean, μ (mu)

-	 Variance, $`σ^2`$.

Our task is to maintain a μ and $`σ^2`$ that parameterize the Gaussian that serves as our best estimate of the location of the object that we are trying to localize.

The expression inside the exponential shows that we are taking the squared difference of our query point, x, and our mean, μ, and dividing this squared difference by the variance, $`σ^2`$  ; the difference between x and μ is normalized by $`σ^2`$ . If x=μ, the numerator in this expression becomes zero, so we have exp(0) = 1. Indicating that the probability should be maximal when x equals the mean of the distribution.

Larger values of $`σ^2`$ indicate large differences between x and μ less than smaller values, in other words, high uncertainty. As a result, Gaussians with large variances produce larger values of f(x) when x is far from the mean than do Gaussians with smaller variances.

Kalmen filters iterate on two main cycles:
-	The first cycle is the **Measurement Update**:

Uses Bayes' rule, which produces a new posterior distribution by taking the product of the prior distribution and the information we gain from our measurement.

-	The second cycle is the **Motion Update**:

AKA the **prediction** - uses the theory of total probability, which produces a new posterior by adding the motion to the prior.

### Designing Kalman filter
When we design a Kalman filter we need 2 things:
1. State Transition Function `x′=Fx+Bu+ν` : models how the state has changed from time K minus one to time K. 
2. Measurement Function `Z = Hx' + w`: models how the measurement is calculated and how it's related to the predicted state x.

***`v (nu)` noise and `omega` noise represent the Stochastic part or in other words, are random noises that affect the prediction and measurement of the steps.***

Other equations for the update and prediction steps can be found [here](https://github.com/raghadeidalmalki/Sensor-Fusion-Nanodegree-Udacity/blob/main/Kalman%20Filters%20/Kalman%20Filter%20Equations/sensor-fusion-ekf-reference.pdf)

## LiDAR and Radar fusion with Extended Kalman Filter (EKF)

The EKF is extended in a sense that it will be capable of handling more complex motion models and measurement models 

![image](https://github.com/user-attachments/assets/b87763b0-6ff6-43d6-8b1d-dff8235475ae)

The Kalman Filter algorithm will go through the following steps:

•	**First measurement** - the filter will receive initial measurements of the bicycle's position relative to the car. These measurements will come from a radar or lidar sensor.

•	**Initialize state and covariance matrices** - the filter will initialize the bicycle's position based on the first measurement.

•	Then the car will receive another sensor measurement after a time period Δt; each time we receive a new measurement from a given sensor the estimation function is triggered.

•	**Predict** - the algorithm will predict where the bicycle will be after time Δt, we predict the bicycle's state and its covariance, we do so by considering the elapsed time between the current and the previous observations. One basic way to predict the bicycle's location after Δt is to assume the bicycle's velocity is constant; thus the bicycle will have moved `velocity * Δt`. 

•	**Update** - the filter compares the "predicted" location with what the sensor measurement says. The predicted location and the measured location are combined to give an updated location. The Kalman filter will put more weight on either the predicted location or the measured location depending on the uncertainty of each value. 

The measurement update step depends on the sensor type; if the current measurement is generated by a lidar sensor, we just apply a standard Kalman filter to update the  state. However, radar measurement involves a nonlinear measurement function, so when we receive radar measurement, we use different EKF equations to handle the measurement update.

•	Then the car will receive another sensor measurement after a time period Δt. The algorithm then does another **predict** and **update** step.


![image](https://github.com/user-attachments/assets/9675ad47-1a74-4179-abc1-a77139a4fd9d)

**Definition of Variables:** 

•	`x` is the **mean state vector**. For an extended Kalman filter, the mean state vector contains information about the object's position and velocity that you are tracking. It is called the "mean" state vector because position and velocity are represented by a gaussian distribution with mean `x`.

•	`P` is the **state covariance matrix**, which contains information about the uncertainty of the object's position and velocity. You can think of it as containing standard deviations.

•	`k` represents **time steps**. So `xk` refers to the object's position and velocity vector at time `k`.

•	The notation `k+1∣k` refers to the prediction step. At time `k+1`, you receive a sensor measurement. Before considering the sensor measurement to update your belief about the object's position and velocity, you predict where you think the object will be at time `k+1`. You can predict the position of the object at `k+1` based on its position and velocity at time `k`. Hence `xk+1∣k` means that you have predicted where the object will be at `k+1` but have not yet taken the sensor measurement into account.

•	`xk+1` means that you have now predicted where the object will be at time `k+1` and then used the sensor measurement to update the object's position and velocity.



----------------


Deriving the Radar Measurement Function
The measurement function is composed of three components that show how the predicted state, x′=$`(px′,py′,vx′,vy′)^T`$, is mapped into the measurement space, z=$`(ρ,φ,ρ˙)^T`$:
The range, ρ, is the distance to the pedestrian which can be defined as:

ρ = $`\sqrt{px^2+py^2}`$

φ is the angle between ρ and the xx direction and can be defined as:

φ=$`\arctan(py/px)`$

There are two ways to do the range rate ρ(t)˙ derivation:
Generally we can explicitly describe the range, ρ, as a function of time:

ρ(t)= $`\sqrt{px(t)^2+py(t)^2}`$

The range rate, ρ(t)˙, is defined as time rate of change of the range, ρ, and it can be described as the time derivative of ρ:

 ![image](https://github.com/user-attachments/assets/3598b239-87a5-4d8b-93f6-bd07e94e07e3)


For simplicity we just use the following notation:


ρ˙= (Px Vx+Py Vy)/$`\sqrt{Px^2+Py^2}`$
